# WirelessEmotionRecognition
Emotion Recognition plays an important role in understanding human behavior. It finds its utility in various domains such as healthcare, automobile industries, understanding social interactions, fraud detection, and many more. Analyzing a personâ€™s emotions in a controlled environment with various devices has been challenging since it adds to human anxiety, which manipulates the readings. This presents a need to devise ways to recognize and study emotions in a wireless manner. There have been previous works done to predict emotions by obtaining photos of subjects whose facial features were analyzed to identify emotions. Though this is an easier way of obtaining results, the data obtained could be wrong since such features could be faked by people. Physiological signals play an important role here. But obtaining physiological signals like Electrocardiography (ECG), Electroencephalography (EEG), Heart Rate Variability (HRV), Blood Volume Pulse (BVP), Galvanic Skin Response (GSR), Electrodermal analysis (EDA), etc. require dedicated equipment, handling skills, and its knowledge. Moreover, human emotions are contaminated when devices are planted on the body since it produces discomfort for them and thus produces incorrect signals. Both physical and physiological methodologies have their advantages and disadvantages. Taking best from both worlds, this paper proposes a technique for emotion recognition that combines both approaches where both physical and physiological signals are used. We use Remote Photoplethysmography (rPPG) to identify the HRV and HR signals which are analysed and classified for emotion recognition. We have used combination of 2 datasets to increase the class diversity which led to dataset with 6 classes. But this approach also added imbalance and overlap of classes in our dataset. Since we are doing multiclass classification, we use Naive Bayes classifier, KNN classifier and random forest classification. Further more, we have applied one vs rest (OVR) strategy with binary classifiers like Logistic regression, and Support Vector Machines (SVM) classifiers are used. We have observed that OVR logistic regression gave accuracy 42.5\% and f1 score of 41.42\%, whereas naive bayes classifier performed lower than logistic regression with accuracy and f1 score of 35.4\%. It was also found that undersampling performed better than oversampling results using SMOTE.
